{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uf4EI65f2pfw"
      },
      "source": [
        "# classification_models\n",
        "*   arboles de decision\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "71dzNQJhcdeY"
      },
      "source": [
        "# Preparacion Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lJnUnKb2nFM"
      },
      "outputs": [],
      "source": [
        "# Tratamiento de datos\n",
        "# ------------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Gráficos\n",
        "# ------------------------------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocesado y modelado\n",
        "# ------------------------------------------------------------------------------\n",
        "# sklearn : scikit learn (paquete de ciencia de datos)\n",
        "from sklearn.model_selection import train_test_split # párticion de datos\n",
        "from sklearn.tree import DecisionTreeClassifier # modelo classifier\n",
        "from sklearn.tree import plot_tree # grafica de modelo\n",
        "from sklearn.tree import export_graphviz # grafica de modelo\n",
        "from sklearn.tree import export_text # grafica de modelo\n",
        "from sklearn.model_selection import GridSearchCV # tuneo de hiper parametros \n",
        "from sklearn.compose import ColumnTransformer # transformacion de variablees\n",
        "from sklearn.preprocessing import OneHotEncoder # transformacion de variablees dummies\n",
        "from sklearn.metrics import accuracy_score # metrica aciertos/totalobservaciones\n",
        "from sklearn.metrics import confusion_matrix # matriz con evaluacion de predicciones\n",
        "\n",
        "# Configuración warnings\n",
        "# ------------------------------------------------------------------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('once')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## problema"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El set de datos Carseats, original del paquete de R ISLR y accesible en Python a través de statsmodels.datasets.get_rdataset, contiene información sobre la venta de sillas infantiles en 400 tiendas distintas. Para cada una de las 400 tiendas se han registrado 11 variables. Se pretende generar un modelo de clasificación que permita predecir si una tienda tiene ventas altas (Sales > 8) o bajas (Sales <= 8) en función de todas las variables disponibles."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "carseats = sm.datasets.get_rdataset(\"Carseats\", \"ISLR\")\n",
        "datos = carseats.data # cargamos los datos en objeto datos\n",
        "print(carseats.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Como Sales es una variable continua y el objetivo del estudio es clasificar las tiendas según si venden mucho o poco, se crea una nueva variable dicotómica (0, 1) llamada ventas_altas.\n",
        "\n",
        "datos['ventas_altas'] = np.where(datos.Sales > 8, 1, 0) # np.where ifelse de numpy\n",
        "# Una vez creada la nueva variable respuesta se descarta la original\n",
        "datos = datos.drop(columns = 'Sales')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos['ventas_altas'].value_counts() # contar por clases 1 y 0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ajuste del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datos para entrenamiento : TRAIN\n",
        "# datos para validacion : TEST\n",
        "\n",
        "\n",
        "# División de los datos en train y test\n",
        "# ------------------------------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                        datos.drop(columns = 'ventas_altas'), # las variables independientes o X\n",
        "                                        datos['ventas_altas'], # la variable que quiero predecir o la Y\n",
        "                                        random_state = 123 # semillas aleatorias \n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modelado de procesamiento de datos\n",
        "\n",
        "# One-hot-encoding de las variables categóricas\n",
        "# ------------------------------------------------------------------------------\n",
        "# Se identifica el nobre de las columnas numéricas y categóricas\n",
        "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
        "numeric_cols = X_train.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
        "\n",
        "# Se indica la acción a aplicar :  one-hot-encoding solo a las columnas categóricas\n",
        "preprocessor = ColumnTransformer(\n",
        "                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
        "                    remainder='passthrough'\n",
        "               )\n",
        "\n",
        "# Una vez que se ha definido el objeto ColumnTransformer, con el método fit()\n",
        "# se aprenden las transformaciones con los datos de entrenamiento y se aplican a\n",
        "# los dos conjuntos con transform(). Ambas operaciones a la vez con fit_transform().\n",
        "X_train_prep = preprocessor.fit_transform(X_train) # ajuste y transforme/aplique transformacion\n",
        "X_test_prep  = preprocessor.transform(X_test) # aplique transformacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir el output del ColumnTransformer en dataframe y añadir el nombre de las columnas\n",
        "# ------------------------------------------------------------------------------\n",
        "# Nombre de todas las columnas\n",
        "encoded_cat = preprocessor.named_transformers_['onehot'].get_feature_names_out(cat_cols)\n",
        "labels = np.concatenate([numeric_cols, encoded_cat])\n",
        "\n",
        "# Conversión a dataframe\n",
        "X_train_prep = pd.DataFrame(X_train_prep, columns=labels)\n",
        "X_test_prep  = pd.DataFrame(X_test_prep, columns=labels)\n",
        "X_train_prep.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creación del modelo\n",
        "# ------------------------------------------------------------------------------\n",
        "modelo = DecisionTreeClassifier(\n",
        "    # hiperparametros\n",
        "            max_depth         = 5,  # maxima profundidad\n",
        "            criterion         = 'gini', # criterio\n",
        "            random_state      = 123 #semilla aleatoria para uso academico\n",
        "          )\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "# ------------------------------------------------------------------------------\n",
        "modelo.fit(X_train_prep, y_train) # aqui se entrenó el modelo con los datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estructura del árbol creado\n",
        "# ------------------------------------------------------------------------------\n",
        "fig, ax = plt.subplots(figsize=(13, 6))\n",
        "\n",
        "print(f\"Profundidad del árbol: {modelo.get_depth()}\")\n",
        "print(f\"Número de nodos terminales: {modelo.get_n_leaves()}\")\n",
        "\n",
        "plot = plot_tree(\n",
        "            decision_tree = modelo,\n",
        "            feature_names = labels.tolist(),\n",
        "            class_names   = 'ventas_altas',\n",
        "            filled        = True,\n",
        "            impurity      = False,\n",
        "            fontsize      = 7,\n",
        "            ax            = ax\n",
        "       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0 : no es ventas altas (186)\n",
        "# 1 : es ventas altas (114)\n",
        "unos = 114\n",
        "total = 186+114\n",
        "w = unos/total\n",
        "w"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicción y evaluación del modelo\n",
        "\n",
        "Se evalúa la capacidad predictiva del árbol inicial calculando el accuracy en el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pruning (const complexity pruning) por validación cruzada\n",
        "# ------------------------------------------------------------------------------\n",
        "# Error de test del modelo\n",
        "#-------------------------------------------------------------------------------\n",
        "predicciones = modelo.predict(X = X_test_prep,) # obtener predicciones\n",
        "\n",
        "print(\"Matriz de confusión\")\n",
        "print(\"-------------------\")\n",
        "confusion_matrix(\n",
        "    y_true    = y_test,\n",
        "    y_pred    = predicciones\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "aciertos = 44 + 27\n",
        "total = 44+27+23+6\n",
        "accuracy =  aciertos /total\n",
        "accuracy*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# El modelo inicial es capaz de predecir correctamente un % de las observaciones del conjunto de test.\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "            y_true    = y_test,\n",
        "            y_pred    = predicciones,\n",
        "            normalize = True\n",
        "           )\n",
        "print(f\"El accuracy de test es: {100 * accuracy} %\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Podado del árbol (pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Post pruning (const complexity pruning) por validación cruzada\n",
        "# ------------------------------------------------------------------------------\n",
        "# Valores de ccp_alpha evaluados\n",
        "param_grid = {'ccp_alpha':np.linspace(0, 5, 10)} # parametro complejidad\n",
        "\n",
        "# Búsqueda por validación cruzada\n",
        "grid = GridSearchCV( # tunear/ buscar combinación de hiperparametros \n",
        "        # El árbol se crece al máximo posible antes de aplicar el pruning\n",
        "        estimator = DecisionTreeClassifier( # modelo claisficador/ regresor\n",
        "                            max_depth         = None,\n",
        "                            min_samples_split = 2,\n",
        "                            min_samples_leaf  = 1,\n",
        "                            random_state      = 123\n",
        "                       ),\n",
        "        param_grid = param_grid,\n",
        "        scoring    = 'accuracy',\n",
        "        cv         = 10, # validacion cruzada \n",
        "        refit      = True,\n",
        "        return_train_score = True\n",
        "      )\n",
        "\n",
        "grid.fit(X_train_prep, y_train) # ajustamos el modelo con las indicaciones de busqueda de parametros\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 3.84)) # ajustar tamaño del visort del grafico\n",
        "scores = pd.DataFrame(grid.cv_results_)\n",
        "scores.plot(x='param_ccp_alpha', y='mean_train_score', yerr='std_train_score', ax=ax)\n",
        "scores.plot(x='param_ccp_alpha', y='mean_test_score', yerr='std_test_score', ax=ax)\n",
        "ax.set_title(\"Error de validacion cruzada vs hiperparámetro ccp_alpha\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mejor valor ccp_alpha encontrado\n",
        "# ------------------------------------------------------------------------------\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estructura del árbol final\n",
        "# ------------------------------------------------------------------------------\n",
        "modelo_final = grid.best_estimator_  # seleccione el el mejor modelo con los parametros optimos \n",
        "print(f\"Profundidad del árbol: {modelo_final.get_depth()}\")\n",
        "print(f\"Número de nodos terminales: {modelo_final.get_n_leaves()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error de test del modelo final\n",
        "#-------------------------------------------------------------------------------\n",
        "predicciones = modelo_final.predict(X = X_test_prep)\n",
        "\n",
        "accuracy = accuracy_score(\n",
        "            y_true    = y_test,\n",
        "            y_pred    = predicciones,\n",
        "            normalize = True\n",
        "           )\n",
        "print(f\"El accuracy de test es: {100 * accuracy} %\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importancia de predictores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Importancia de los predictores en el modelo\")\n",
        "print(\"-------------------------------------------\")\n",
        "importancia_predictores = pd.DataFrame(\n",
        "                            {'predictor': labels.tolist(),\n",
        "                             'importancia': modelo_final.feature_importances_}\n",
        "                            )\n",
        "importancia_predictores.sort_values('importancia', ascending=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicción de probabilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predicción de probabilidades\n",
        "#-------------------------------------------------------------------------------\n",
        "predicciones = modelo.predict_proba(X = X_test_prep)\n",
        "predicciones[:5, 1:] # quedarse con las dos probabilidad p(0) y p(1) es redundante suele usarse solo p(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clasificación empleando la clase de mayor probabilidad\n",
        "# ------------------------------------------------------------------------------\n",
        "df_predicciones = pd.DataFrame(data=predicciones, columns=['0', '1'])\n",
        "df_predicciones['clasificacion_default_0.5'] = np.where(df_predicciones['0'] > df_predicciones['1'], 0, 1)\n",
        "df_predicciones.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clasificación final empleando un threshold de 0.8 para la clase 1.\n",
        "# ------------------------------------------------------------------------------\n",
        "df_predicciones['clasificacion_custom_0.8'] = np.where(df_predicciones['1'] > 0.8, 1, 0) # np.where son el ifelse de numpy para utilizar threshold : umbral = 0.8\n",
        "df_predicciones.iloc[5:10, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clasificación final empleando un threshold de 0.8 para la clase 1.\n",
        "# ------------------------------------------------------------------------------\n",
        "df_predicciones['clasificacion_fal'] = np.where(df_predicciones['1'] > 0, 1, 0) # np.where son el ifelse de numpy para utilizar threshold \n",
        "df_predicciones.iloc[5:10, 1:]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cdeiZxD02pLf"
      },
      "source": [
        "## Bibliografía"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yTifdGxy2qzu"
      },
      "source": [
        "\n",
        "* https://www.cienciadedatos.net/documentos/py07_arboles_decision_python.html"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "f128fe3ab5917b826f85fed29f7e6d5cdf9b8c96daddc94321e327dfff04eefa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
